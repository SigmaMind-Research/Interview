# Computer Vision Intern Home Assessment Task

## Task Description: Handwritten Digit Classification using Vision Transformer (ViT)

### Objective:
The goal of this task is to assess your ability to implement a Vision Transformer (ViT) model for handwritten digit classification using a dataset such as MNIST. You are expected to create a small Python script or Jupyter notebook that demonstrates your understanding of ViT architecture, training procedures, and the ability to analyze and visualize the results.

### Task Steps:

1. **Data Preparation:**
   - Download the MNIST dataset (or any other handwritten digit dataset).
   - Preprocess the dataset as needed, including normalization and splitting into training and testing sets.

2. **Vision Transformer Implementation:**
   - Implement a Vision Transformer model using TensorFlow or PyTorch.
   - Define the necessary components of the ViT architecture, including self-attention mechanisms.
   - Configure the model for handwritten digit classification.

3. **Model Training:**
   - Train the Vision Transformer model on the training set.
   - Monitor and log relevant training metrics, such as accuracy and loss.
   - Save the trained model for later use.

4. **Evaluation:**
   - Evaluate the trained model on the testing set.
   - Report the accuracy and any additional evaluation metrics you find relevant.

5. **Visualization:**
   - Visualize some predictions made by the model on a sample of the testing dataset.
   - Include visualizations of attention maps or other relevant visualizations to demonstrate the ViT's capabilities.

### Submission Guidelines:
- Submit your solution as a well-documented Python script or Jupyter notebook.
- Include comments to explain your code and choices.
- Clearly indicate the sections for data preparation, model implementation, training, evaluation, and visualization.
- If you use external libraries or pre-trained models, provide instructions on how to install or access them.

### Bonus (Optional):
- Experiment with hyperparameter tuning to improve model performance.
- Compare the Vision Transformer's performance with a traditional CNN architecture for digit classification.

### Evaluation Criteria:
Your submission will be evaluated based on the following criteria:
- Correctness and functionality of the implemented Vision Transformer.
- Clarity and documentation of your code.
- Accuracy and evaluation metrics on the testing dataset.
- Quality and relevance of visualizations.

### Submission Deadline:
Please submit your completed task by 8th Jan 2024. If you have any questions or need clarification, feel free to reach out. and pleaase create a public repo of submission and send the link to linkedin.

Good luck, and we look forward to reviewing your submission!
